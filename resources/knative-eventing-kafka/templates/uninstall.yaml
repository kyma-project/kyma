# About:
# This pre-delete job removes all kafkachannel custom resources
# It does so by using a job which is executed before the helm chart is deleted

apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ .Release.Name }}-cr-delete
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Release.Name }}-cr-delete
  annotations:
    helm.sh/hook: pre-delete
    helm.sh/hook-delete-policy: "hook-succeeded,before-hook-creation"
    # everything without a dependency has weight 0
    helm.sh/hook-weight: "0"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: {{ .Release.Name }}-cr-delete
  labels:
    app: {{ .Release.Name }}-cr-delete
  annotations:
    helm.sh/hook: pre-delete
    helm.sh/hook-delete-policy: "hook-succeeded,before-hook-creation"
    helm.sh/hook-weight: "0"
rules:
- apiGroups: ["knativekafka.kyma-project.io"]
  resources: ["kafkachannels"]
  verbs: ["list", "delete"]
- apiGroups: ["apiextensions.k8s.io"]
  resources: ["customresourcedefinitions"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: {{ .Release.Name }}-cr-delete
  labels:
    app: {{ .Release.Name }}-cr-delete
  annotations:
    helm.sh/hook: pre-delete
    helm.sh/hook-delete-policy: "hook-succeeded,before-hook-creation"
    helm.sh/hook-weight: "1"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: {{ .Release.Name }}-cr-delete
subjects:
  - kind: ServiceAccount
    name: {{ .Release.Name }}-cr-delete
    namespace: {{ .Release.Namespace }}
---
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Release.Name }}-cr-delete
  namespace: {{ .Release.Namespace }}
  labels:
    kyma-project.io/uninstall: eventing
  annotations:
    helm.sh/hook: pre-delete
    helm.sh/hook-delete-policy: "hook-succeeded,before-hook-creation"
    # dependent on clusterrole, clusterrolebinding, serviceaccount
    # => hook-weight=min(hook-weight)+1
    helm.sh/hook-weight: "2"
    sidecar.istio.io/inject: "false"
spec:
  backoffLimit: 1
  template:
    metadata:
      annotations:
        sidecar.istio.io/inject: "false"
      labels:
        kyma-project.io/uninstall: eventing
      name: {{ .Release.Name }}-cr-delete
    spec:
      serviceAccountName: {{ .Release.Name }}-cr-delete
      restartPolicy: Never
      containers:
        - name: {{ .Release.Name }}-cr-delete
          image: eu.gcr.io/kyma-project/incubator/develop/k8s-tools:20201125-6e6f9030
          command:
            - "/bin/bash"
          args:
            - "-c"
            - |
{{ .Files.Get "uninstall.sh" | indent 14 }}
          # use last chunk of container log output for terminal log
          # source: https://kubernetes.io/docs/tasks/debug-application-cluster/determine-reason-pod-failure/#customizing-the-termination-message
          terminationMessagePolicy: "FallbackToLogsOnError"
          resources:
            requests:
              cpu: 200m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 128Mi

