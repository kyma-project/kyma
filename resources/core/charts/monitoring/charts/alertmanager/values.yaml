## Alertmanager configuration directives
## Ref: https://prometheus.io/docs/alerting/configuration/
##
config:
  global:
    resolve_timeout: 5m
  route:
    receiver: 'null'
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 1h # change to 10m to test
    group_by: ['cluster','pod','job','alertname']
    # All alerts that do not match the following child routes
    # will remain at the root node and be dispatched to 'default-receiver'
    routes:
    - receiver: 'null'
      match:
        alertname: DeadMansSwitch
    # - receiver: 'team-YOUR-TEAM-victorOps'
    #   continue: true # If continue: is set to false it will stop after the first matching.
    #   match:
    #     alertname: PodNotRunning
    # - receiver: 'team-YOUR-TEAM-slack'
    #   continue: true # If continue: is set to false it will stop after the first matching.
    #   match:
    #     alertname: PodNotRunning
  receivers:
  - name: 'null'
  # - name: 'team-YOUR-TEAM-victorOps'
  #   victorops_configs:
  #     - api_key: API_VICTOROPS_TOKEN
  #       send_resolved: true
  #       api_url: https://alert.victorops.com/integrations/generic/20131114/alert/
  #       routing_key: YOUR-TEAM-ROUTING-KEY
  #       state_message: 'Alert: {{ .CommonLabels.alertname }}. Summary:{{ .CommonAnnotations.summary }}. RawData: {{ .CommonLabels }}'
  # - name: 'team-YOUR-TEAM-slack'
  #   slack_configs:
  #   - channel: '#YOU_CHANNEL'
  #     send_resolved: true
  #     api_url: https://hooks.slack.com/services/XXXXXXXXX/XXXXXXXXX/XXXXXXXXXXXXXXXXXX #Your slack Webhook URL
  #     icon_emoji: ":ghost:"
  #     title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Monitoring Event Notification'
  #     text: "<!channel> \nsummary: {{ .CommonAnnotations.summary }}\ndescription: {{ .CommonAnnotations.description }}"

## Alertmanager template files to include
#
templateFiles: {}
#
# An example template:
#   template_1.tmpl: |-
#       {{ define "cluster" }}{{ .ExternalURL | reReplaceAll ".*alertmanager\\.(.*)" "$1" }}{{ end }}
#
#       {{ define "slack.myorg.text" }}
#       {{- $root := . -}}
#       {{ range .Alerts }}
#         *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
#         *Cluster:*  {{ template "cluster" $root }}
#         *Description:* {{ .Annotations.description }}
#         *Graph:* <{{ .GeneratorURL }}|:chart_with_upwards_trend:>
#         *Runbook:* <{{ .Annotations.runbook }}|:spiral_note_pad:>
#         *Details:*
#           {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
#           {{ end }}

## External URL at which Alertmanager will be reachable
##
externalUrl: ""

## If true, create a serviceMonitor for alertmanager
##
selfServiceMonitor: true

## Alertmanager container image
##
image:
  repository: quay.io/prometheus/alertmanager
  tag: v0.14.0

## Labels to be added to the Alertmanager
##
labels: {}

virtualservice:
  ## If true, Alertmanager VirtualService will be created
  ##
  enabled: false

  ## Annotations for Alertmanager VirtualService
  ##
  annotations: {}

  ## Labels to be added to the VirtualService
  ##
  labels: {}

  fqdn: ""

## Node labels for Alertmanager pod assignment
## Ref: https://kubernetes.io/docs/user-guide/node-selection/
##
nodeSelector: {}

## Tolerations for use with node taints
## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: {}
  #  - key: "key"
  #    operator: "Equal"
  #    value: "value"
  #    effect: "NoSchedule"



## If true, the Operator won't process any Alertmanager configuration changes
##
paused: false

## Number of Alertmanager replicas desired
##
replicaCount: 1

## Pod anti-affinity can prevent the scheduler from placing Alertmanager replicas on the same node.
## The default value "soft" means that the scheduler should *prefer* to not schedule two replica pods onto the same node but no guarantee is provided.
## The value "hard" means that the scheduler is *required* to not schedule two replica pods onto the same node.
## The value "" will disable pod anti-affinity so that no anti-affinity rules will be configured.
podAntiAffinity: "soft"

## Resource limits & requests
## Ref: https://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 200Mi
  limits:
    memory: 400Mi

service:
  ## Annotations to be added to the Service
  ##
  annotations: {}

  ## Cluster-internal IP address for Alertmanager Service
  ##
  clusterIP: ""

  ## List of external IP addresses at which the Alertmanager Service will be available
  ##
  externalIPs: []

  ## Labels to be added to the Service
  ##
  labels: {}

  ## External IP address to assign to Alertmanager Service
  ## Only used if service.type is 'LoadBalancer' and supported by cloud provider
  ##
  loadBalancerIP: ""

  ## List of client IPs allowed to access Alertmanager Service
  ## Only used if service.type is 'LoadBalancer' and supported by cloud provider
  ##
  loadBalancerSourceRanges: []

  ## Port to expose on each node
  ## Only used if service.type is 'NodePort'
  ##
  nodePort: 30903

  ## Service type
  ##
  type: ClusterIP

## If true, create & use RBAC resources
##
rbacEnable: true

## Alertmanager StorageSpec for persistent data
## Ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/storage.md
##
storageSpec: {}
#  volumeClaimTemplate:
#    spec:
#      storageClassName: gluster
#      accessModes: ["ReadWriteOnce"]
#      resources:
#        requests:
#          storage: 50Gi
#    selector: {}

# default rules are in templates/alertmanager.rules.yaml
# prometheusRules: {}
