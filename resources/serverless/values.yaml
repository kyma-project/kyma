# Default values for serverless.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

fullnameOverride: "serverless"

injectCerts:
  image:
    repository: "eu.gcr.io/kyma-project/test-infra/alpine-kubectl"
    tag: "v20200617-32c1f3ff"
    pullPolicy: IfNotPresent

runtimeMigration:
  image:
    repository: "eu.gcr.io/kyma-project/test-infra/alpine-kubectl"
    tag: "v20200617-32c1f3ff"
    pullPolicy: IfNotPresent

tests:
  enabled: true
  long:
    initTimeout: 120s
    resources:
      requests:
        memory: 128Mi
        cpu: 100m
      limits:
        memory: 256Mi
        cpu: 200m
    image:
      repository: "eu.gcr.io/kyma-project/test-infra/alpine-kubectl"
      tag: "v20200617-32c1f3ff"
      pullPolicy: IfNotPresent
    namespace: "long-running-function-test"
    name: longrun

  image:
    repository: "eu.gcr.io/kyma-project/function-controller-test"
    tag: "1088c1af"
    pullPolicy: IfNotPresent
  disableConcurrency: false
  restartPolicy: Never
  resources:
    requests:
      memory: 32Mi
      cpu: 100m
    limits:
      memory: 64Mi
      cpu: 200m
  envs:
    waitTimeout: 15m
    verifySSL: "false"
    verbose: "true"
    gitServer:
      image: "eu.gcr.io/kyma-project/gitserver"
      tag: "c0aa144a"
      repoName: "function"

global:
  commonLabels:
    app: '{{ template "name" . }}'
    version: "{{ .Values.images.manager.tag }}"
    app.kubernetes.io/name: '{{ template "name" . }}'
    app.kubernetes.io/instance: "{{ .Release.Name }}"
    app.kubernetes.io/managed-by: "{{ .Release.Service }}"
    app.kubernetes.io/version: "{{ .Values.images.manager.tag }}"
    helm.sh/chart: '{{ include "chart" . }}'
  dockerServicePort: 5000
  ingress:
    domainName:

images:
  manager:
    repository: "eu.gcr.io/kyma-project/function-controller"
    tag: "1088c1af"
    pullPolicy: IfNotPresent
  runtimes:
    nodejs12:
      repository: "eu.gcr.io/kyma-project/function-runtime-nodejs12"
      tag: "2bba165a"
    nodejs10:
      repository: "eu.gcr.io/kyma-project/function-runtime-nodejs10"
      tag: "2bba165a"
    python38:
      repository: "eu.gcr.io/kyma-project/function-runtime-python38"
      tag: "2bba165a"

deployment:
  replicas: 1
  labels: {}
  annotations: {}
  extraProperties: {}

pod:
  labels: {}
  annotations:
    sidecar.istio.io/inject: "false"
  extraProperties:
    terminationGracePeriodSeconds: 10

containers:
  manager:
    resources:
      limits:
        cpu: 100m
        memory: 126Mi #This is temporary. helm3 is using secrets as storage by default. I talked already with michalhudy to exclude secrets with helm labels from watching.
      requests:
        cpu: 10m
        memory: 32Mi
    extraProperties: {}
    envs:
      runtimeConfigMapName:
        value: dockerfile-nodejs-12
      buildRequestsCPU:
        value: 700m
      buildRequestsMemory:
        value: 700Mi
      buildLimitsCPU:
        value: 1100m
      buildLimitsMemory:
        value: 1100Mi
      configMapRequeueDuration:
        value: 5m
      secretRequeueDuration:
        value: 5m
      serviceAccountRequeueDuration:
        value: 5m
      namespaceExcludedNames:
        value: "istio-system,knative-eventing,knative-serving,kube-node-lease,kube-public,kube-system,kyma-installer,kyma-integration,kyma-system,natss,compass-system"
      imageRegistryDockerConfigSecretName:
        value: '{{ template "fullname" . }}-image-pull-secret'
      imagePullAccountName:
        value: '{{ template "fullname" . }}'
      targetCPUUtilizationPercentage:
        value: "50"
      kserviceRequeueDuration:
        value: 5m
      functionRequeueDuration:
        value: 5m
      functionBuildExecutorArgs:
        value: "--insecure,--skip-tls-verify,--skip-unused-stages,--log-format=text,--cache=true"
      functionBuildExecutorImage:
        value: gcr.io/kaniko-project/executor:v0.22.0
      functionBuildRepoFetcherImage:
        value: eu.gcr.io/kyma-project/function-build-init:1088c1af

services:
  manager:
    type: ClusterIP
    labels: {}
    annotations: {}

metrics:
  enabled: true
  manager:
    port:
      name: http-metrics
      port: 8080
      targerPort: 8080
      protocol: TCP
  serviceMonitor:
    create: true
    scrapeInterval: 30s
    labels: {}
    annotations: {}
  pod:
    labels: {}
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "8080"
      prometheus.io/path: "/metrics"

backendModule:
  enabled: true

clusterMicroFrontend:
  enabled: true

grafanaDashboard:
  enabled: true

usageKind:
  name: serverless-function

dockerRegistry:
  enableInternal: true
  username: "{{ randAlphaNum 20 | b64enc }}" # for gcr "_json_key"
  password: "{{ randAlphaNum 40 | b64enc }}" # for gcr data from json key
  internalServerAddress: '{{ template "registry-fullname" . }}.{{ .Release.Namespace }}.svc.cluster.local:{{ .Values.global.dockerServicePort }}'
  serverAddress: "registry.{{ .Values.global.ingress.domainName -}}"
  registryAddress: "registry.{{ .Values.global.ingress.domainName -}}"

docker-registry:
  fullnameOverride: "serverless-docker-registry"
  secrets:
    haSharedSecret: "secret"
    htpasswd: "generated-in-init-container"
  extraVolumeMounts:
    - name: htpasswd-data
      mountPath: /data
  extraVolumes:
    - name: registry-credentials
      secret:
        secretName: serverless-registry-credentials
        items:
          - key: username
            path: username.txt
          - key: password
            path: password.txt
    - name: htpasswd-data
      emptyDir: {}

webhook:
  enabled: true
  fullnameOverride: "serverless-webhook"
