rbac:
  create: true
  pspEnabled: true

networkPolicy:
  enabled: false

serviceAccount:
  create: true
  name:

# enable tracing for debug, need install jaeger and specify right jaeger_agent_host
tracing:
  jaegerAgentHost:

loki:
  podManagementPolicy: OrderedReady
  nameOverride: loki
  replicas: 1
  minReadySeconds: 0
  terminationGracePeriodSeconds: 30
  deploymentStrategy: RollingUpdate
  port: 3100

  updateStrategy:
    type: RollingUpdate

  podLabels: {}

  securityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001

  extraArgs: {}
    # log.level: debug

  image:
    repository: grafana/loki
    tag: v0.3.0
    pullPolicy: Always # Always pull while in BETA

  # user: user
  # password: pass
  service:
    port: 3100
    scheme: http
    #user: user
    #password: pass
    annotations:
      auth.istio.io/3100: NONE
    #  prometheus.io/scrape: "true"
    #  prometheus.io/port: "http-metrics"
    labels: {}

  readinessProbe:
    httpGet:
      path: /ready
      port: http
    initialDelaySeconds: 45

  livenessProbe:
    httpGet:
      path: /ready
      port: http
    initialDelaySeconds: 45

  resources:
    limits:
      cpu: 300m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi

  ## Pod Annotations
  podAnnotations:
    sidecar.istio.io/inject: "true"

  ## Deployment annotations
  annotations: {}

  ## Assign a PriorityClassName to pods if set
  # priorityClassName:

  ## Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  #
  nodeSelector: {}

  ## Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []

  ## Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ##
  affinity: {}
    # podAntiAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #   - labelSelector:
    #       matchExpressions:
    #       - key: app
    #         operator: In
    #         values:
    #         - loki
  #     topologyKey: "kubernetes.io/hostname"

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ## If you set enabled as "True", you need :
  ## - create a pv which above 10Gi and has same namespace with loki
  ## - keep storageClassName same with below setting
  persistence:
    enabled: true
    accessModes:
      - ReadWriteOnce
    size: 10Gi
    storageClassName: ""
    # annotations: {}
    # subPath: ""
    # existingClaim:

  config:
    auth_enabled: false
    ingester:
      chunk_idle_period: 15m
      chunk_block_size: 262144
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1
        ## Different ring configs can be used. E.g. Consul
        # ring:
        #   store: consul
        #   replication_factor: 1
        #   consul:
        #     host: "consul:8500"
        #     prefix: ""
        #     httpclienttimeout: "20s"
        #     consistentreads: true
    limits_config:
      enforce_metric_name: false
      reject_old_samples: true
      reject_old_samples_max_age: 168h
    schema_config:
      configs:
        - from: 2018-04-15
          store: boltdb
          object_store: filesystem
          schema: v9
          index:
            prefix: index_
            period: 24h
    server:
      http_listen_port: 3100
    storage_config:
      boltdb:
        directory: /data/loki/index
      filesystem:
        directory: /data/loki/chunks
    chunk_store_config:
      max_look_back_period: 0
    table_manager:
      retention_deletes_enabled: true 
      retention_period: 24h

promtail:
  nameOverride: promtail
  deploymentStrategy: RollingUpdate

  entryParser: docker

  image:
    repository: grafana/promtail
    tag: v0.3.0
    pullPolicy: Always # Always pull while in BETA

  volumes:
    - name: varlog
      hostPath:
        path: /var/log
    - name: varlibdockercontainers
      hostPath:
        path: /var/lib/docker/containers

  volumeMounts:
    - name: varlog
      mountPath: /var/log
    - name: varlibdockercontainers
      mountPath: /var/lib/docker/containers
      readOnly: true

  readinessProbe:
    failureThreshold: 5
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1

  livenessProbe: {}

  resources:
    limits:
      cpu: 300m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi

  securityContext:
    readOnlyRootFilesystem: true
    runAsGroup: 0
    runAsUser: 0

  # This should match config.server.http_listen_port
  port: 3101

  ## Pod Labels
  podLabels: {}

  ## Assign a PriorityClassName to pods if set
  # priorityClassName:

  ## Pod Annotations
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "http-metrics"
  #For pods running sidecars w/o service there's a problem with envoy readiness probe.
  #Details https://github.com/istio/istio/issues/9504#issuecomment-439432130
    readiness.status.sidecar.istio.io/applicationPorts: ""

  ## Deployment annotations
  annotations: {}

  ## Assign a PriorityClassName to pods if set
  # priorityClassName:

  ## Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  #
  nodeSelector: {}

  ## Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations:
    - key: node-role.kubernetes.io/master
      effect: NoSchedule

  ## Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ##
  affinity: {}

  pipelineStages:
  - docker: {}

  # Custom scrape_configs to override the default ones in the configmap
  scrapeConfigs: []

  config:
    client:
      # Maximum wait period before sending batch
      batchwait: 1s
      # Maximum batch size to accrue before sending, unit is byte
      batchsize: 102400

      # Maximum time to wait for server to respond to a request
      timeout: 10s

      backoff_config:
        # Initial backoff time between retries
        minbackoff: 100ms
        # Maximum backoff time between retries
        maxbackoff: 5s
        # Maximum number of retires when sending batches, 0 means infinite retries
        maxretries: 5

      # The labels to add to any time series or alerts when communicating with loki
      external_labels: {}

    server:
      http_listen_port: 3101
    positions:
      filename: /run/promtail/positions.yaml
    target_config:
      # Period to resync directories being watched and files being tailed
      sync_period: 10s

fluentbit:
  nameOverride: fluent-bit
  image:
    repository: fluent/fluent-bit
    tag: 1.2.1
    pullPolicy: Always

# name of log collector to be installed, by default will be grafana promtail installed, other supported collector is "fluent-bit"
logcollector:
  name: promtail

logui:
  replicaCount: 1
  image:
    name: log-ui
    tag: da918ff4
    dir:
    pullPolicy: Always
  service:
    name: nginx
    type: ClusterIP
    externalPort: 80
    internalPort: 80
  resources: {}
  nameOverride: log-ui

global:
  containerRegistry:
    path: eu.gcr.io/kyma-project
  logging_integration_tests:
    name: logging-integration-tests
    dir: 
    version: 5a771fdf
  logging:
    promtail:
      config:
        name: promtail-k8s-1-14.yaml
    