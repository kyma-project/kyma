apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ template "exporter-kubelets.fullname" . }}
  labels:
    app: "alertmanager"
    chart: {{ .Chart.Name }}-{{ .Chart.Version }}
    heritage: {{ .Release.Service }}
    prometheus: {{ .Release.Name }}
    release: {{ .Release.Name }}
    role: alert-rules
spec:
  groups:
  - name: kubelet.rules
    rules:
    - alert: KubeNodeNotReady
      expr: kube_node_status_condition{condition="Ready",status="true"} == 0
      for: 1h
      labels:
        severity: warning
      annotations:
        message: The Kubelet on {{`{{ $labels.node }}`}} has not checked in with the API or has set itself to NotReady, for more than an hour
        summary: Node status is NotReady
    - alert: KubeManyNodesNotReady
      expr: count(sum by (node)(kube_node_status_condition{condition="Ready",status="true"})) / count(sum by(node)(kube_node_info)) * 100 < 100
      for: 30m
      labels:
        severity: critical
      annotations:
        message: '{{`{{ $value }}`}}% of Kubernetes nodes are not ready'
    - alert: K8SKubeletDown
      expr: count(up{job="kubelet"} == 0) / count(up{job="kubelet"}) * 100 > 3
      for: 1h
      labels:
        severity: warning
      annotations:
        message: Prometheus failed to scrape {{`{{ $value }}`}}% of kubelets.
        summary: Prometheus failed to scrape
    - alert: K8SKubeletDown
      expr: (absent(up{job="kubelet"} == 1) or count(up{job="kubelet"} == 0) / count(up{job="kubelet"}))
        * 100 > 10
      for: 1h
      labels:
        severity: critical
      annotations:
        message: Prometheus failed to scrape {{`{{ $value }}`}}% of kubelets, or all Kubelets
          have disappeared from service discovery.
        summary: Many Kubelets cannot be scraped
    - alert: K8SKubeletTooManyPods
      expr: kubelet_running_pod_count > 100
      for: 10m
      labels:
        severity: warning
      annotations:
        message: Kubelet {{`{{$labels.instance}}`}} is running {{`{{$value}}`}} pods, close
          to the limit of 110
        summary: Kubelet is close to pod limit
    - alert: KubeClientErrors
      annotations:
        message: Kubernetes API server client '{{`{{ $labels.job }}`}}/{{`{{ $labels.instance }}`}}' is experiencing {{`{{ printf "%0.0f" $value }}`}}% errors.'
      expr: |-
        (sum(rate(rest_client_requests_total{code=~"5.."}[5m])) by (instance, job)
          /
        sum(rate(rest_client_requests_total[5m])) by (instance, job))
        * 100 > 1
      for: 15m
      labels:
        severity: warning
    - alert: KubeClientErrors
      annotations:
        message: Kubernetes API server client '{{`{{ $labels.job }}`}}/{{`{{ $labels.instance }}`}}' is experiencing {{`{{ printf "%0.0f" $value }}`}} errors / second.
      expr: sum(rate(ksm_scrape_error_total{job="kube-state-metrics"}[5m])) by (instance, job) > 0.1
      for: 15m
      labels:
        severity: warning