---
apiVersion: v1
kind: Namespace
metadata:
  name: kyma-installer
  labels:
    istio-injection: disabled
    kyma-project.io/installation: ""
---
apiVersion: v1
kind: LimitRange
metadata:
  name: kyma-default
  namespace: kyma-installer
  labels:
    kyma-project.io/installation: ""
spec:
  limits:
  - max:
      memory: 2048Mi # Maximum memory that a container can request
    default:
      # If a container does not specify memory limit, this default value will be applied.
      # If a container tries to allocate more memory, container will be OOM killed.
      memory: 256Mi
    defaultRequest:
      # If a container does not specify memory request, this default value will be applied.
      # The scheduler considers this value when scheduling a container to a node.
      # If a node has not enough memory, such pod will not be created.
      memory: 32Mi
    type: Container
---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: installations.installer.kyma-project.io
  labels:
    kyma-project.io/installation: ""
spec:
  group: installer.kyma-project.io
  version: v1alpha1
  scope: Namespaced
  names:
    kind: Installation
    singular: installation
    plural: installations
    shortNames: ['installation']
---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: releases.release.kyma-project.io
  labels:
    kyma-project.io/installation: ""
spec:
  group: release.kyma-project.io
  version: v1alpha1
  scope: Namespaced
  names:
    kind: Release
    singular: release
    plural: releases
    shortNames: ['release']
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: all-psp
rules:
- apiGroups: ["extensions","policy"]
  resources: ["podsecuritypolicies"]
  verbs: ["use"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: all-psp
subjects:
- kind: ServiceAccount
  name: helm-certs-job-sa
  namespace: kyma-installer
roleRef:
  kind: ClusterRole
  name: all-psp
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kyma-installer
  namespace: kyma-installer
  labels:
    kyma-project.io/installation: ""
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kyma-installer
  namespace: kyma-installer
  labels:
    kyma-project.io/installation: ""
spec:
  selector:
    matchLabels:
      name: kyma-installer
  # Installer is designed to be run as a single instance only
  # We enforce it by changing default rolling update to recreate startegy.
  # With that k8s will first delete old pod and then provision new one during upgrade.
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        name: kyma-installer
    spec:
      serviceAccountName: kyma-installer
      initContainers:
      - name: 2to3
        image: eu.gcr.io/kyma-project/test-infra/alpine-kubectl:v20200617-32c1f3ff
        terminationMessagePolicy: "FallbackToLogsOnError"
        command:
        - /bin/bash
        - -c
        - |
          set -e
          HELM_2_BINARY=$(which helm)
          HELM_3_BINARY=$(which helm3)
          SECRET_NAME="helm-secret"
          NAMESPACE="kyma-installer"
          CHART_BLACKLIST=( "gateway-0.0.1" "application-0.0.1" )

          echo "---> Install requirements"
          apk add git jq

          echo "---> Get HELM_2 certs"
          ${HELM_2_BINARY} init -c

          if [[ $(kubectl get -n kube-system deploy tiller-deploy -o name) ]]; then
            if [[ $(kubectl get -n "${NAMESPACE}" secret "${SECRET_NAME}" -o name) ]]; then
              kubectl get -n "${NAMESPACE}" secret "${SECRET_NAME}" -o jsonpath="{.data['global\\.helm\\.ca\\.crt']}" | base64 --decode > "$(helm home)/ca.pem"
              kubectl get -n "${NAMESPACE}" secret "${SECRET_NAME}" -o jsonpath="{.data['global\\.helm\\.tls\\.crt']}" | base64 --decode > "$(helm home)/cert.pem"
              kubectl get -n "${NAMESPACE}" secret "${SECRET_NAME}" -o jsonpath="{.data['global\\.helm\\.tls\\.key']}" | base64 --decode > "$(helm home)/key.pem"
            else
              exit 0
            fi
          else
            echo "------> No Tiller deployment found, exiting gracefully"
            exit 0
          fi

          echo "---> Get current releases"
          set -o pipefail
          ${HELM_2_BINARY} ls --tls --all --output json | jq '.Releases[] | .Name + " " + .Namespace + " " + .Chart' | tr -d '"' > helm2-releases
          set +o pipefail
          if [[ ! $(${HELM_3_BINARY} plugin list | grep '2to3') ]]; then
            echo "---> Get migration plugin"
            ${HELM_3_BINARY} plugin install https://github.com/helm/helm-2to3.git

            echo "---> Migrate config files"
            yes | ${HELM_3_BINARY} 2to3 move config
          fi

          echo "---> Migrate releases"

          while read line; do
            release=$(echo $line | cut -d " " -f1)
            ns=$(echo $line | cut -d " " -f2)
            chart=$(echo $line | cut -d " " -f3)

            if [[ " ${CHART_BLACKLIST[@]} " =~ " ${chart} " ]]; then
              echo "------> Release ${release} is blacklisted by ${chart}"
              continue
            fi

            if [[ $(${HELM_3_BINARY} get all ${release} -n ${ns} 2> /dev/null) ]]; then
              echo "------> Release ${release} in ns ${ns} already migrated!"
            else
              ${HELM_3_BINARY} 2to3 convert ${release}
            fi
          done < helm2-releases
        resources:
          limits:
            memory: 1024Mi
          requests:
            memory: 512Mi
      containers:
      - name: kyma-installer-container
        image: eu.gcr.io/kyma-project/kyma-installer:1.15.0-rc2
        imagePullPolicy: IfNotPresent
        args:
          - -overrideLogFile=/app/overrides.txt
          - -helmDebugMode=true
        resources:
          requests:
            memory: 512Mi
          limits:
            memory: 2Gi
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: kyma-installer-reader
  labels:
    kyma-project.io/installation: ""
rules:
- apiGroups: ["*"]
  resources: ["*"]
  verbs: ["*"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: kyma-installer
  labels:
    kyma-project.io/installation: ""
subjects:
- kind: ServiceAccount
  name: kyma-installer
  namespace: kyma-installer
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kyma-installer-reader
